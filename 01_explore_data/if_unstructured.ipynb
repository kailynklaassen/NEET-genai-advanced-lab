{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d62d931-047d-4971-8c56-5f5f23abb08d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create an unstructured data pipeline for GenAI retrievers\n",
    "\n",
    "Before building vector search indexes, it's essential to first prepare your unstructured data through a dedicated data engineering step. This involves ingesting, cleaning, and transforming raw documents into a structured formatâ€”typically chunked, metadata-enriched, and stored in Delta tables. This foundation ensures your GenAI retrievers operate on high-quality, queryable content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c796fd03-3a8f-4975-8f8d-efabaa5cfa1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../00_setup/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1b4a2dc-f22b-473a-81d2-d4879f6fe4e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT path\n",
    "FROM READ_FILES('/Volumes/{catalog_name}/{schema_name}/pdfs/', format => 'binaryFile')\n",
    "LIMIT 2\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63eddf45-ecbb-42b9-8051-0072fd190ad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog_name\", catalog_name)\n",
    "dbutils.widgets.text(\"schema_name\", schema_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c3ea9d4-84f6-45e4-917c-12dff6f8e2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT path\n",
    "FROM READ_FILES('/Volumes/' || :catalog_name || '/' || :schema_name || '/pdfs/', format => 'binaryFile')\n",
    "LIMIT 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98748197-2215-4fb4-8730-db456e2ecfa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Extracting the information using `ai_parse_document`\n",
    "Databricks provides a builtin `ai_parse_document` function, leveraging AI to analyze and extract PDF information as text. This makes it super easy to ingest unstructured information!\n",
    "\n",
    "- Easy to adopt. Recommended for the POC and long-term. \n",
    "- This AI function can work with PDF, JPG, and PNG. The product team recently added PPTX as well. \n",
    "\n",
    "https://docs.databricks.com/aws/en/sql/language-manual/functions/ai_parse_document?language=SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db449579-a8fd-4a4e-93bd-aa977c05fb0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT path FROM READ_FILES('/Volumes/databricks_workshop/jywu/pdfs/', format => 'binaryFile') LIMIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74a8b4a7-8fe5-4b44-a23b-48208d865488",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT ai_parse_document(content) AS parsed_document\n",
    "FROM READ_FILES('/Volumes/databricks_workshop/jywu/pdfs/', format => 'binaryFile') LIMIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9ab8156-9c78-446b-b696-4ea0ee32b37e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH corpus AS (\n",
    "  SELECT\n",
    "    path,\n",
    "    ai_parse_document(content) AS parsed\n",
    "  FROM\n",
    "    READ_FILES('/Volumes/databricks_workshop/jywu/pdfs/', format => 'binaryFile')\n",
    ")\n",
    "SELECT\n",
    "  path,\n",
    "  parsed:document:pages,\n",
    "  parsed:document:elements,\n",
    "  parsed:corrupted_data,\n",
    "  parsed:error_status,\n",
    "  parsed:metadata\n",
    "FROM corpus;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb7cd6a8-409e-4286-b725-b8d465d76368",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- unflatten json\n",
    "WITH corpus AS (\n",
    "  SELECT\n",
    "    path,\n",
    "    ai_parse_document(content) AS parsed\n",
    "  FROM READ_FILES('/Volumes/databricks_workshops/jywu/pdfs/', format => 'binaryFile')\n",
    ")\n",
    "SELECT\n",
    "  c.path                      AS doc_uri,\n",
    "  e.col.bbox[0].page_id       AS page_id,\n",
    "  e.col.content,\n",
    "  e.col.description,\n",
    "  e.col.type,\n",
    "  e.col.bbox[0].coord[0]      AS x0,\n",
    "  e.col.bbox[0].coord[1]      AS y0,\n",
    "  e.col.bbox[0].coord[2]      AS x1,\n",
    "  e.col.bbox[0].coord[3]      AS y1\n",
    "FROM corpus c\n",
    "LATERAL VIEW explode(\n",
    "  from_json(\n",
    "    variant_get(\n",
    "      variant_get(c.parsed, '$.document', 'VARIANT'),\n",
    "      '$.elements',\n",
    "      'STRING'\n",
    "    ),\n",
    "    'ARRAY<STRUCT<\n",
    "        page_id INT,\n",
    "        content STRING,\n",
    "        description STRING,\n",
    "        type STRING,\n",
    "        bbox ARRAY<STRUCT<\n",
    "          page_id INT,\n",
    "          coord ARRAY<DOUBLE>\n",
    "        >>\n",
    "    >>'\n",
    "  )\n",
    ") e\n",
    "LIMIT 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ec05053-1f73-4632-bba7-6938e409a37e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    " -- combine them together for chunking\n",
    "WITH corpus AS (\n",
    "  SELECT\n",
    "    path,\n",
    "    ai_parse_document(content) AS parsed\n",
    "  FROM READ_FILES('/Volumes/databricks_workshop/jywu/pdfs/', format => 'binaryFile')\n",
    ")\n",
    "SELECT\n",
    "  path AS doc_uri,\n",
    "  array_join(\n",
    "    transform(\n",
    "      filter(\n",
    "        parsed:document:elements::ARRAY<STRUCT<content:STRING, description:STRING>>,\n",
    "        e -> e.content IS NOT NULL OR e.description IS NOT NULL\n",
    "      ),\n",
    "      e -> coalesce(e.content, e.description)\n",
    "    ),\n",
    "    '\\n'\n",
    "  ) AS content\n",
    "FROM corpus;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50fe767e-d81f-4a2a-8ac4-2bef1ecbee11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Python UDF\n",
    "Databricks' notebook [template](https://docs.databricks.com/aws/en/notebooks/source/generative-ai/unstructured-data-pipeline.html) to parse, chunk and create index. PDF, DOCX, HTML, TXT, MD, JSON are included in the template and the logic can be extended.\n",
    "- Recommended for quick trial and error as it requires additional code.\n",
    "- This is a more hard-coded way but more robust as well. \n",
    "- Search for `file_parser` function to take a closer look."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": "A10",
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "if_unstructured",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
